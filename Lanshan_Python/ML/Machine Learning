
# 1、逻辑回归（Logistic Regression）


[Logistic（逻辑斯蒂）函数浅谈]：

https://zhuanlan.zhihu.com/p/630739668

原理讲解
在模式识别问题中，所关心的量是分类，比如是否会患有某种疾病，这时就不能用简单的线性回归来完成这个问题了。为了解决次问题，我们引入了非线性激活函数g : R D → ( 0 , 1 ) g:{\mathbb R}^D\to(0,1)g:R 
D
 →(0,1)来预测类别标签的后验概率p ( y = 1 ∣ x ) p(y=1|\bf x)p(y=1∣x)，其中y ∈ { 0 , 1 } y\in\{0,1\}y∈{0,1}，函数g gg的作用是把线性函数的值域从实数区间挤压到0和1之间
在Logistic回归中，激活函数的表达式为：
Logistic 激活函数又叫作 Sigmoid 函数，它将实数值压缩进 0 到 1 的区间内，还可以在预测概率的输出层中使用。该函数将大的负数转换为趋近于 0，将大的正数转换为趋近于 1。

**优点：**

Sigmoid函数的优点在于它可导，并且值域在0到1之间，使得神经元的输出标准化。

**缺点：**

（1）梯度消失：Sigmoid 函数值在趋近 0 和 1 的时候函数值会变得平坦，梯度趋近于 0。

（2）不以零为中心：sigmoid函数的输出恒为正值，不是以零为中心的，这会导致权值更新时只能朝一个方向更新，从而影响收敛速度。

（3）计算成本高昂：exp() 函数与其他非线性激活函数相比，计算成本高昂。

（4）梯度爆炸：x值在趋近0的左右两边时，会造成梯度爆炸情况
                        


Logistic 分布是由其位置和尺度参数定义的连续分布。Logistic 分布的形状与正态分布的形状相似，但是 Logistic 分布的尾部更长，所以我们可以使用 Logistic 分布来建模比正态分布具有更长尾部和更高波峰的数据分布。在深度学习中常用到的 Sigmoid 函数就是 Logistic 的分布函数在 
 的特殊形式。
###### 1、逻辑回归（Logistic Regression） 
1. [逻辑回归](#1、逻辑回归（Logistic Regression）)
2、朴素贝叶斯
3、感知机
4、支持向量机（SVM）
5、决策树
6、GBDT

7、XGBoost
8、LightGBM
9、PCA
10、K-means
11、EM算法
12、FM
13、梯度下降法
14、正则化
15、样本不均衡
16、特征工程
17、模型集成
18、kaggle
