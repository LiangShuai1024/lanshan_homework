# 基于lstm的时间序列预测

### 数据格式转换
```
x_train = torch.from_numpy(x_train).type(torch.Tensor)
x_test = torch.from_numpy(x_test).type(torch.Tensor)
# 真实的数据
y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)
y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)
y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)
y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)
```
```
# 输入的维度为1，只有Close收盘价
input_dim = 1
# 隐藏层特征的维度
hidden_dim = 32
# 循环的layers
num_layers = 2
# 预测后一天的收盘价
output_dim = 1
num_epochs = 100
```
### 模型的定义
```
class LSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):
        super(LSTM, self).__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
```

### 模型的前向传播

```
    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        out = self.fc(out[:, -1, :])
        return out

```

### 创建模型实例
```
model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)
```
### 定义均方误差损失函数作为模型的损失函数
```
criterion = torch.nn.MSELoss()
```
### 定义均方误差损失函数作为模型的损失函数，学习率lr为0.01
```
optimiser = torch.optim.Adam(model.parameters(), lr=0.01)
```
这是训练集预测结果(红)与原数据(蓝)部分对比
![图片01](/Lanshan_Python/holidayRNN/训练集预测(部分).png)
虽然偏差不小，但起码大体的趋势表现出来了

这是模型训练过程中，loss的变化情况
![图片02](/Lanshan_Python/holidayRNN/loss变化图.png)
可以看出，模型的拟合效果还不出错

这是预测集的表现结果(红)与原数据(绿)的对比
![图片03](/Lanshan_Python/holidayRNN/预测结果图.png)
